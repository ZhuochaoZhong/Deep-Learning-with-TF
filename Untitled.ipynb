{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('stars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (K)</th>\n",
       "      <th>Luminosity(L/Lo)</th>\n",
       "      <th>Radius(R/Ro)</th>\n",
       "      <th>Absolute magnitude(Mv)</th>\n",
       "      <th>Star type</th>\n",
       "      <th>Star color</th>\n",
       "      <th>Spectral Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3068</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>16.12</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3042</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>16.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>18.70</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1939</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>20.06</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature (K)  Luminosity(L/Lo)  Radius(R/Ro)  Absolute magnitude(Mv)  \\\n",
       "0             3068          0.002400        0.1700                   16.12   \n",
       "1             3042          0.000500        0.1542                   16.60   \n",
       "2             2600          0.000300        0.1020                   18.70   \n",
       "3             2800          0.000200        0.1600                   16.65   \n",
       "4             1939          0.000138        0.1030                   20.06   \n",
       "\n",
       "   Star type Star color Spectral Class  \n",
       "0          0        Red              M  \n",
       "1          0        Red              M  \n",
       "2          0        Red              M  \n",
       "3          0        Red              M  \n",
       "4          0        Red              M  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('/', '-')\n",
    "# data.pop('hotel_name')\n",
    "# data['score'] = data['score'] - 1\n",
    "# data['user_country'][103] = 'India'\n",
    "# data['member_years'][75] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_country = data['user_country'].unique()\n",
    "period_of_stay = data['period_of_stay'].unique()\n",
    "pool = data['pool'].unique()\n",
    "traveler_type = data['traveler_type'].unique()\n",
    "gym = data['gym'].unique()\n",
    "tennis_court = data['tennis_court'].unique()\n",
    "spa = data['spa'].unique()\n",
    "casino = data['casino'].unique()\n",
    "free_internet = data['free_internet'].unique()\n",
    "hotel_stars = data['hotel_stars'].unique()\n",
    "user_continent = data['user_continent'].unique()\n",
    "review_month = data['review_month'].unique()\n",
    "review_weekday = data['review_weekday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 train examples\n",
      "81 validation examples\n",
      "101 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(df, batch_size=32):\n",
    "    \n",
    "    df = df.copy()\n",
    "    labels = df.pop('score')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))    \n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df_to_dataset(train)\n",
    "val_ds = df_to_dataset(val)\n",
    "test_ds = df_to_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['user_country', 'nr_reviews', 'nr_hotel_reviews', 'helpful_votes', 'period_of_stay', 'traveler_type', 'pool', 'gym', 'tennis_court', 'spa', 'casino', 'free_internet', 'hotel_stars', 'nr_rooms', 'user_continent', 'member_years', 'review_month', 'review_weekday']\n",
      "A batch of Spa: tf.Tensor(\n",
      "[b'YES' b'YES' b'YES' b'YES' b'YES' b'YES' b'YES' b'NO' b'YES' b'YES'\n",
      " b'YES' b'YES' b'YES' b'YES' b'YES' b'YES' b'NO' b'NO' b'YES' b'NO' b'YES'\n",
      " b'YES' b'YES' b'YES' b'YES' b'NO' b'YES' b'NO' b'YES' b'YES' b'YES' b'NO'], shape=(32,), dtype=string)\n",
      "A batch of Scores: tf.Tensor([4 0 3 3 4 2 3 1 3 3 3 4 4 4 4 3 4 4 4 4 4 2 1 2 4 3 1 4 4 3 4 4], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "    print('A batch of Spa:', feature_batch['spa'])\n",
    "    print('A batch of Scores:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(train_ds))[0]\n",
    "def demo(feature_column):\n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'user_country': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'nr_reviews': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'nr_hotel_reviews': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'helpful_votes': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'period_of_stay': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'traveler_type': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'pool': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'gym': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'tennis_court': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'spa': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'casino': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'free_internet': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'hotel_stars': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'nr_rooms': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'user_continent': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'member_years': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'review_month': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'review_weekday': TensorSpec(shape=(None,), dtype=tf.string, name=None)},\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='user_country', vocabulary_list=('USA', 'UK', 'Canada', 'India', 'Australia', 'New Zeland', 'Ireland', 'Egypt', 'Finland', 'Kenya', 'Jordan', 'Netherlands', 'Syria', 'Scotland', 'South Africa', 'Swiss', 'United Arab Emirates', 'Hungary', 'China', 'Greece', 'Mexico', 'Croatia', 'Germany', 'Malaysia', 'Thailand', 'Phillippines', 'Israel', 'Belgium', 'Puerto Rico', 'Switzerland', 'Norway', 'France', 'Spain', 'Singapore', 'Brazil', 'Costa Rica', 'Iran', 'Saudi Arabia', 'Honduras', 'Denmark', 'Taiwan', 'Hawaii', 'Kuwait', 'Czech Republic', 'Japan', 'Korea', 'Italy'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='period_of_stay', vocabulary_list=('Dec-Feb', 'Mar-May', 'Jun-Aug', 'Sep-Nov'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='pool', vocabulary_list=('NO', 'YES'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='traveler_type', vocabulary_list=('Friends', 'Business', 'Families', 'Solo', 'Couples'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='gym', vocabulary_list=('YES', 'NO'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='tennis_court', vocabulary_list=('NO', 'YES'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='spa', vocabulary_list=('NO', 'YES'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='casino', vocabulary_list=('YES', 'NO'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='free_internet', vocabulary_list=('YES', 'NO'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='hotel_stars', vocabulary_list=(3, 4, 5), dtype=tf.int64, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='user_continent', vocabulary_list=('North America', 'Europe', 'Asia', 'Oceania', 'Africa', 'South America'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='review_month', vocabulary_list=('January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='review_weekday', vocabulary_list=('Thursday', 'Friday', 'Saturday', 'Tuesday', 'Wednesday', 'Sunday', 'Monday'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n"
     ]
    }
   ],
   "source": [
    "col_names = ['user_country', 'period_of_stay', 'pool', 'traveler_type', 'gym',\n",
    "              'tennis_court', 'spa', 'casino', 'free_internet', 'hotel_stars', \n",
    "              'user_continent', 'review_month', 'review_weekday']\n",
    "\n",
    "vocab_list = [user_country, period_of_stay, pool, traveler_type, gym,\n",
    "              tennis_court, spa, casino, free_internet, hotel_stars, \n",
    "              user_continent, review_month, review_weekday]\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for i in range(len(col_names)):\n",
    "    col = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_names[i], vocab_list[i]\n",
    "    )\n",
    "    one_hot_col = feature_column.indicator_column(col)\n",
    "    print(one_hot_col)\n",
    "    feature_columns.append(one_hot_col)\n",
    "    \n",
    "for col in ['nr_reviews', 'nr_hotel_reviews', 'helpful_votes', 'nr_rooms', 'member_years']:\n",
    "    feature_columns.append(feature_column.numeric_column(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()\n",
    "model = tf.keras.Sequential([\n",
    "    feature_layer,\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 2.5542 - accuracy: 0.0559 - val_loss: 2.3277 - val_accuracy: 0.0693\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0214 - accuracy: 0.0559 - val_loss: 2.1736 - val_accuracy: 0.0693\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9318 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9270 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.0559 - val_loss: 2.0404 - val_accuracy: 0.0693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbef497c390>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=test_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
